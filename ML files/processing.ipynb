{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction, preprocessing, and context-aware chunking complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz\n",
    "\n",
    "import re\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def extract_and_chunk_with_context(pdf_path, output_folder, target_size=(224, 224)):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_data = []\n",
    "    heading_regex = r\"^[A-Z][A-Z0-9\\s\\-:]+$\"\n",
    "    supported_formats = [\"jpeg\", \"jpg\", \"png\"]\n",
    "    current_chunk = {\"type\": \"text\", \"content\": \"\", \"context\": \"\"}\n",
    "    current_heading = None\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_text = page.get_text(\"text\")\n",
    "        lines = page_text.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if re.match(heading_regex, line.strip()):  \n",
    "                if current_chunk[\"content\"].strip():\n",
    "                    extracted_data.append(current_chunk)\n",
    "                    current_chunk = {\"type\": \"text\", \"content\": \"\", \"context\": \"\"}\n",
    "                current_heading = line.strip()\n",
    "                current_chunk[\"context\"] = f\"{current_heading} (Page {page_num + 1})\"\n",
    "            else:\n",
    "                current_chunk[\"content\"] += line + \" \"\n",
    "\n",
    "       \n",
    "        for img_idx, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image.get(\"image\")\n",
    "            image_ext = base_image.get(\"ext\", \"unknown\").lower()\n",
    "\n",
    "            if not image_bytes or image_ext not in supported_formats:\n",
    "                print(f\"Skipping unsupported or invalid image on Page {page_num + 1}, Image {img_idx + 1} (Format: {image_ext})\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "              \n",
    "                image = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
    "                image_resized = image.resize(target_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "                \n",
    "                image_filename = f\"page_{page_num + 1}_img_{img_idx + 1}.{image_ext}\"\n",
    "                image_path = os.path.join(output_folder, image_filename)\n",
    "                image_resized.save(image_path)\n",
    "\n",
    "            \n",
    "                image_context = f\"{current_heading or 'Page'} {page_num + 1}: Image {img_idx + 1}\"\n",
    "                extracted_data.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"content\": image_path,\n",
    "                    \"page_no\": page_num + 1,\n",
    "                    \"context\": image_context\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image on Page {page_num + 1}, Image {img_idx + 1}: {e}\")\n",
    "                continue\n",
    "\n",
    "  \n",
    "    if current_chunk[\"content\"].strip():\n",
    "        extracted_data.append(current_chunk)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "\n",
    "pdf_path = r\"D:\\Projects\\test-generator-llm-rag\\jee-content\\pyq\\dokumen.pub_43-years-jee-advanced-1978-2020-jee-main-chapterwise-amp-topicwise-solved-papers-chemistry-16nbsped-8194767733-9788194767732.pdf\"\n",
    "output_folder = r\"D:/Projects/test-generator-llm-rag/output_folder/PYQ16\"\n",
    "target_size = (224, 224)\n",
    "\n",
    "chunked_data = extract_and_chunk_with_context(pdf_path, output_folder, target_size=target_size)\n",
    "\n",
    "with open(os.path.join(output_folder, \"chunked_data.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunked_data, f, indent=4)\n",
    "\n",
    "print(\"Extraction, preprocessing, and context-aware chunking complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import os\n",
    "output_folder = r\"D:\\Projects\\test-generator-llm-rag\\output_folder\\PYQ16\"\n",
    "def embed_chunks(chunks):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if chunk[\"type\"] == \"text\":\n",
    "            embedding = model.encode(chunk[\"content\"])\n",
    "            embeddings.append({\n",
    "                \"embedding\": embedding.tolist(),\n",
    "                \"content\": chunk[\"content\"],\n",
    "                \"context\": chunk[\"context\"]\n",
    "            })\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "with open(os.path.join(output_folder, \"chunked_data.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    chunked_data = json.load(f)\n",
    "\n",
    "embedded_data = embed_chunks(chunked_data)\n",
    "\n",
    "with open(os.path.join(output_folder, \"embedded_data.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(embedded_data, f, indent=4)\n",
    "\n",
    "print(\"Embedding complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    
    
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(index_name, dimension=384)  \n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "def upload_to_pinecone(embedded_data):\n",
    "    vectors = []\n",
    "    for i, item in enumerate(embedded_data):\n",
    "        vectors.append({\n",
    "            \"id\": f\"chunk-{i}\",\n",
    "            \"values\": item[\"embedding\"],\n",
    "            \"metadata\": {\n",
    "                \"content\": item[\"content\"],\n",
    "                \"context\": item[\"context\"]\n",
    "            }\n",
    "        })\n",
    "\n",
    "    index.upsert(vectors=vectors)\n",
    "\n",
    "upload_to_pinecone(embedded_data)\n",
    "\n",
    "print(\"Data successfully uploaded to Pinecone!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'types' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpinecone\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pinecone, ServerlessSpec\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CLIPProcessor, CLIPModel\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\__init__.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_template_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     31\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     36\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\chat_template_utils.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m     43\u001b[0m BASIC_TYPES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, Any, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Extracts the initial segment of the docstring, containing the function description\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py:2016\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m   2011\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   2012\u001b[0m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[0;32m   2013\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   2014\u001b[0m \n\u001b[0;32m   2015\u001b[0m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[1;32m-> 2016\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _VF \u001b[38;5;28;01mas\u001b[39;00m _VF, functional \u001b[38;5;28;01mas\u001b[39;00m functional  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m   2017\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   2020\u001b[0m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\functional.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, List, Optional, Sequence, Tuple, TYPE_CHECKING, Union\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _VF, Tensor\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     Buffer \u001b[38;5;28;01mas\u001b[39;00m Buffer,\n\u001b[0;32m      4\u001b[0m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[0;32m      5\u001b[0m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[0;32m      6\u001b[0m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     attention \u001b[38;5;28;01mas\u001b[39;00m attention,\n\u001b[0;32m     11\u001b[0m     functional \u001b[38;5;28;01mas\u001b[39;00m functional,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bilinear, Identity, LazyLinear, Linear  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     CELU,\n\u001b[0;32m      5\u001b[0m     ELU,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     Threshold,\n\u001b[0;32m     33\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceLikeType\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Buffer, Parameter\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackwardHook, RemovableHandle\n\u001b[0;32m     33\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_module_forward_pre_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregister_module_forward_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:295\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;66;03m# Subtypes which have __tensor_flatten__ and __tensor_unflatten__.\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mTensorWithFlatten\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mProtocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__tensor_flatten__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTuple\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:323\u001b[0m, in \u001b[0;36mTensorWithFlatten\u001b[1;34m()\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdim\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m--> 323\u001b[0m         dtype: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241m.\u001b[39m_dtype,\n\u001b[0;32m    324\u001b[0m         non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m         copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    327\u001b[0m         memory_format: Optional[torch\u001b[38;5;241m.\u001b[39mmemory_format] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    339\u001b[0m         memory_format: Optional[torch\u001b[38;5;241m.\u001b[39mmemory_format] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    340\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch' has no attribute 'types' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU detected:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "\n",
    "api_key = \"pcsk_4Bujbk_2GmM5SvXzqNjUiAmd1BHFZFYP8H2cpnXeogv7k2AKP1F8QUk4Q18xEpRu2AGcgX\"\n",
    "environment = \"us-east-1\"\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "\n",
    "index_name = \"test-generator-1\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=512,  \n",
    "        metric=\"cosine\", \n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=environment,\n",
    "        )\n",
    "    )\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "def generate_and_store_embeddings(json_path, index):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for item in data:\n",
    "        content_type = item[\"type\"]\n",
    "        context = item[\"context\"]\n",
    "        page_no = item[\"page_no\"]\n",
    "\n",
    "        try:\n",
    "            if content_type == \"text\":\n",
    "                text_content = item[\"content\"]\n",
    "                inputs = clip_processor(text=[text_content], return_tensors=\"pt\", truncation=True)\n",
    "                text_embedding = clip_model.get_text_features(**inputs).detach().numpy().flatten()\n",
    "\n",
    "                index.upsert([\n",
    "                    (f\"text\", text_embedding.tolist(), {\"type\": \"text\", \"context\": context})\n",
    "                ])\n",
    "\n",
    "            elif content_type == \"image\":\n",
    "                image_path = item[\"content\"]\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
    "                image_embedding = clip_model.get_image_features(**inputs).detach().numpy().flatten()\n",
    "\n",
    "                index.upsert([\n",
    "                    (f\"image-{page_no}-{os.path.basename(image_path)}\", image_embedding.tolist(), {\"type\": \"image\", \"context\": context, \"page_no\": page_no})\n",
    "                ])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {content_type}: {e}\")\n",
    "\n",
    "output_folder = r\"D:\\Projects\\test-generator-llm-rag\\output_folder\"\n",
    "\n",
    "def process_all_folders(output_folder, index):\n",
    "    for folder_name in os.listdir(output_folder):\n",
    "        folder_path = os.path.join(output_folder, folder_name)\n",
    "        json_path = os.path.join(folder_path, \"chunked_data.json\")\n",
    "        if os.path.exists(json_path):\n",
    "            print(f\"Processing and storing embeddings for: {json_path}\")\n",
    "            generate_and_store_embeddings(json_path, index)\n",
    "\n",
    "process_all_folders(output_folder, index)\n",
    "\n",
    "print(\"All embeddings stored in Pinecone!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
